{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ETL Pipeline Demonstration\n",
        "\n",
        "This notebook demonstrates the ETL pipeline that processes CSV and JSON files and loads them into a SQL database.\n",
        "\n",
        "## Features:\n",
        "- **CSV Processing**: Extracts, transforms, and loads CSV data to `test` table\n",
        "- **JSON Processing**: Extracts, transforms, and normalizes JSON data into `users`, `telephone_numbers`, and `jobs_history` tables\n",
        "- **PII Masking**: Automatically masks sensitive information\n",
        "- **Data Validation**: Ensures data types and constraints are met\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine, text\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add src to path\n",
        "sys.path.insert(0, str(Path.cwd()))\n",
        "\n",
        "print(\"✓ Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Initialize the ETL Pipeline\n",
        "\n",
        "We'll use SQLite for simplicity, but the pipeline supports any SQL database via SQLAlchemy connection strings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.pipeline import ETLPipeline\n",
        "\n",
        "# Initialize pipeline with SQLite database\n",
        "db_connection_string = 'sqlite:///etl_database.db'\n",
        "pipeline = ETLPipeline(db_connection_string)\n",
        "\n",
        "print(f\"✓ ETL Pipeline initialized\")\n",
        "print(f\"✓ Database: {db_connection_string}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check CSV file\n",
        "csv_file = Path('data/test.csv')\n",
        "print(f\"CSV file exists: {csv_file.exists()}\")\n",
        "print(f\"CSV file size: {csv_file.stat().st_size / (1024*1024):.2f} MB\")\n",
        "\n",
        "# Preview first few rows\n",
        "if csv_file.exists():\n",
        "    df_preview = pd.read_csv(csv_file, nrows=5)\n",
        "    print(\"\\nFirst 5 rows:\")\n",
        "    print(df_preview)\n",
        "    print(f\"\\nColumns: {list(df_preview.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process CSV file\n",
        "print(\"Processing CSV file...\")\n",
        "pipeline.process_csv(str(csv_file), 'test')\n",
        "print(\"✓ CSV processing completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Connect to database and query test table\n",
        "engine = create_engine(db_connection_string)\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    # Get row count\n",
        "    result = conn.execute(text(\"SELECT COUNT(*) as count FROM test\"))\n",
        "    row_count = result.fetchone()[0]\n",
        "    print(f\"Total rows in 'test' table: {row_count}\")\n",
        "    \n",
        "    # Get sample data\n",
        "    result = conn.execute(text(\"SELECT * FROM test LIMIT 5\"))\n",
        "    columns = result.keys()\n",
        "    rows = result.fetchall()\n",
        "    \n",
        "    print(\"\\nSample data from 'test' table:\")\n",
        "    df_test = pd.DataFrame(rows, columns=columns)\n",
        "    print(df_test)\n",
        "    \n",
        "    # Check data types\n",
        "    print(\"\\nData types:\")\n",
        "    result = conn.execute(text(\"PRAGMA table_info(test)\"))\n",
        "    schema = result.fetchall()\n",
        "    for col in schema:\n",
        "        print(f\"  {col[1]}: {col[2]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check JSON file\n",
        "json_file = Path('data/test.json')\n",
        "print(f\"JSON file exists: {json_file.exists()}\")\n",
        "print(f\"JSON file size: {json_file.stat().st_size / (1024*1024):.2f} MB\")\n",
        "\n",
        "# Preview first record\n",
        "if json_file.exists():\n",
        "    import json\n",
        "    with open(json_file, 'r') as f:\n",
        "        first_line = f.readline()\n",
        "        first_record = json.loads(first_line)\n",
        "        print(\"\\nFirst record structure:\")\n",
        "        print(json.dumps(first_record, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process JSON file\n",
        "print(\"Processing JSON file...\")\n",
        "pipeline.process_json(str(json_file))\n",
        "print(\"✓ JSON processing completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Verify JSON Data in Database\n",
        "\n",
        "Let's verify that the three tables (`users`, `telephone_numbers`, `jobs_history`) were created and populated correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify users table\n",
        "with engine.connect() as conn:\n",
        "    result = conn.execute(text(\"SELECT COUNT(*) as count FROM users\"))\n",
        "    user_count = result.fetchone()[0]\n",
        "    print(f\"Total users: {user_count}\")\n",
        "    \n",
        "    result = conn.execute(text(\"SELECT * FROM users LIMIT 3\"))\n",
        "    columns = result.keys()\n",
        "    rows = result.fetchall()\n",
        "    df_users = pd.DataFrame(rows, columns=columns)\n",
        "    print(\"\\nSample users (with PII masked):\")\n",
        "    print(df_users[['user_id', 'name', 'username', 'national_id']].to_string())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify telephone_numbers table\n",
        "with engine.connect() as conn:\n",
        "    result = conn.execute(text(\"SELECT COUNT(*) as count FROM telephone_numbers\"))\n",
        "    tel_count = result.fetchone()[0]\n",
        "    print(f\"Total telephone numbers: {tel_count}\")\n",
        "    \n",
        "    result = conn.execute(text(\"\"\"\n",
        "        SELECT tn.*, u.name \n",
        "        FROM telephone_numbers tn\n",
        "        JOIN users u ON tn.user_id = u.user_id\n",
        "        LIMIT 5\n",
        "    \"\"\"))\n",
        "    columns = result.keys()\n",
        "    rows = result.fetchall()\n",
        "    df_tel = pd.DataFrame(rows, columns=columns)\n",
        "    print(\"\\nSample telephone numbers (with PII masked):\")\n",
        "    print(df_tel[['user_id', 'name', 'telephone_number']].to_string())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify jobs_history table\n",
        "with engine.connect() as conn:\n",
        "    result = conn.execute(text(\"SELECT COUNT(*) as count FROM jobs_history\"))\n",
        "    job_count = result.fetchone()[0]\n",
        "    print(f\"Total job history records: {job_count}\")\n",
        "    \n",
        "    result = conn.execute(text(\"\"\"\n",
        "        SELECT jh.*, u.name \n",
        "        FROM jobs_history jh\n",
        "        JOIN users u ON jh.user_id = u.user_id\n",
        "        LIMIT 5\n",
        "    \"\"\"))\n",
        "    columns = result.keys()\n",
        "    rows = result.fetchall()\n",
        "    df_jobs = pd.DataFrame(rows, columns=columns)\n",
        "    print(\"\\nSample job history:\")\n",
        "    print(df_jobs[['user_id', 'name', 'occupation', 'start', 'end', 'is_fulltime']].to_string())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Verify Foreign Key Relationships\n",
        "\n",
        "Let's verify that the foreign key relationships are working correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify relationships\n",
        "with engine.connect() as conn:\n",
        "    # Check users with telephone numbers\n",
        "    result = conn.execute(text(\"\"\"\n",
        "        SELECT \n",
        "            u.user_id,\n",
        "            u.name,\n",
        "            COUNT(tn.telephone_number) as phone_count,\n",
        "            COUNT(jh.job_id) as job_count\n",
        "        FROM users u\n",
        "        LEFT JOIN telephone_numbers tn ON u.user_id = tn.user_id\n",
        "        LEFT JOIN jobs_history jh ON u.user_id = jh.user_id\n",
        "        GROUP BY u.user_id, u.name\n",
        "        LIMIT 10\n",
        "    \"\"\"))\n",
        "    columns = result.keys()\n",
        "    rows = result.fetchall()\n",
        "    df_relationships = pd.DataFrame(rows, columns=columns)\n",
        "    print(\"Users with their telephone numbers and job counts:\")\n",
        "    print(df_relationships.to_string())\n",
        "    \n",
        "    print(\"\\n✓ Foreign key relationships verified!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Summary Statistics\n",
        "\n",
        "Let's get a summary of all the data loaded.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics\n",
        "with engine.connect() as conn:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ETL Pipeline Summary\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Test table\n",
        "    result = conn.execute(text(\"SELECT COUNT(*) FROM test\"))\n",
        "    test_count = result.fetchone()[0]\n",
        "    print(f\"\\n✓ Test table: {test_count:,} rows\")\n",
        "    \n",
        "    # Users table\n",
        "    result = conn.execute(text(\"SELECT COUNT(*) FROM users\"))\n",
        "    users_count = result.fetchone()[0]\n",
        "    print(f\"✓ Users table: {users_count:,} rows\")\n",
        "    \n",
        "    # Telephone numbers\n",
        "    result = conn.execute(text(\"SELECT COUNT(*) FROM telephone_numbers\"))\n",
        "    tel_count = result.fetchone()[0]\n",
        "    print(f\"✓ Telephone numbers table: {tel_count:,} rows\")\n",
        "    \n",
        "    # Jobs history\n",
        "    result = conn.execute(text(\"SELECT COUNT(*) FROM jobs_history\"))\n",
        "    jobs_count = result.fetchone()[0]\n",
        "    print(f\"✓ Jobs history table: {jobs_count:,} rows\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"✓ All data successfully loaded and verified!\")\n",
        "    print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Close pipeline\n",
        "pipeline.close()\n",
        "print(\"✓ Pipeline closed successfully\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
