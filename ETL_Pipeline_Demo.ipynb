{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoostCredit ETL Pipeline Demo\n",
    "\n",
    "This notebook demonstrates the ETL pipeline for processing CSV and JSON data.\n",
    "\n",
    "## Pipeline Flow:\n",
    "1. **Extract** → Read data from CSV/JSON files\n",
    "2. **Transform** → Clean, convert types, mask PII\n",
    "3. **Store** → Save to object store (Parquet)\n",
    "4. **Load** → Load from object store to PostgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment variables set\n",
      "✓ Imports successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Reload modules to ensure we have the latest code (important for notebooks)\n",
    "import src.loaders\n",
    "import src.pipeline\n",
    "import src.extractors\n",
    "import src.transformers\n",
    "importlib.reload(src.loaders)\n",
    "importlib.reload(src.pipeline)\n",
    "importlib.reload(src.extractors)\n",
    "importlib.reload(src.transformers)\n",
    "\n",
    "from src.pipeline import Pipeline\n",
    "from src.extractors import CSVExtractor, JSONExtractor\n",
    "from src.transformers import CSVTransformer, JSONTransformer\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['STORE_KEY'] = 'demo_data'\n",
    "os.environ['DB_TYPE'] = 'postgresql'\n",
    "os.environ['DB_HOST'] = 'localhost'\n",
    "os.environ['DB_PORT'] = '5432'\n",
    "os.environ['DB_USER'] = 'etl_user'\n",
    "os.environ['DB_PASSWORD'] = 'etl_password'\n",
    "os.environ['DB_NAME'] = 'etl_database'\n",
    "os.environ['DATA_PATH'] = './data'\n",
    "os.environ['OBJECT_STORE_PATH'] = './output'\n",
    "\n",
    "print(\"✓ Environment variables set\")\n",
    "print(\"✓ Modules reloaded and imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize Pipeline\n",
    "\n",
    "The pipeline handles the complete ETL process automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SQLLoader._build_connection_string() missing 6 required positional arguments: 'db_type', 'db_user', 'db_password', 'db_host', 'db_port', and 'db_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8338/152215251.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✓ Pipeline initialized\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/anserGithub/BoostCredit/src/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCSVTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQLLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/anserGithub/BoostCredit/src/loaders.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Missing required database credentials: DB_HOST, DB_PORT, DB_USER, DB_PASSWORD, DB_NAME\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_connection_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: SQLLoader._build_connection_string() missing 6 required positional arguments: 'db_type', 'db_user', 'db_password', 'db_host', 'db_port', and 'db_name'"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "print(\"✓ Pipeline initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Test Individual Components\n",
    "\n",
    "Let's test each component separately to understand what they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CSV Extractor\n",
    "csv_extractor = CSVExtractor()\n",
    "csv_file = Path('data/test.csv')\n",
    "if csv_file.exists():\n",
    "    sample_data = csv_extractor.extract(str(csv_file))\n",
    "    print(f\"✓ CSV Extracted: {len(sample_data)} rows\")\n",
    "    print(f\"  Columns: {list(sample_data.columns)}\")\n",
    "    print(f\"\\n  First row sample:\")\n",
    "    print(sample_data.head(1))\n",
    "else:\n",
    "    print(\"⚠ CSV file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CSV Transformer\n",
    "csv_transformer = CSVTransformer()\n",
    "if csv_file.exists():\n",
    "    transformed = csv_transformer.transform(sample_data.head(5))\n",
    "    print(\"✓ CSV Transformed\")\n",
    "    print(f\"  Data types converted\")\n",
    "    print(f\"  PII masked (name, address)\")\n",
    "    print(f\"\\n  Transformed sample:\")\n",
    "    print(transformed[['id', 'name', 'created_at', 'is_claimed', 'paid_amount']].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test JSON Extractor\n",
    "json_extractor = JSONExtractor()\n",
    "json_file = Path('data/test.json')\n",
    "if json_file.exists():\n",
    "    json_data = json_extractor.extract(str(json_file))\n",
    "    print(f\"✓ JSON Extracted: {len(json_data)} records\")\n",
    "    print(f\"\\n  First record keys: {list(json_data[0].keys())}\")\n",
    "    print(f\"  Sample user_id: {json_data[0].get('user_id', 'N/A')}\")\n",
    "else:\n",
    "    print(\"⚠ JSON file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test JSON Transformer\n",
    "json_transformer = JSONTransformer()\n",
    "if json_file.exists():\n",
    "    json_transformed = json_transformer.transform(json_data[:2])  # Transform 2 records\n",
    "    print(\"✓ JSON Transformed into 3 tables:\")\n",
    "    print(f\"  - users: {len(json_transformed['users'])} rows\")\n",
    "    print(f\"  - telephone_numbers: {len(json_transformed['telephone_numbers'])} rows\")\n",
    "    print(f\"  - jobs_history: {len(json_transformed['jobs_history'])} rows\")\n",
    "    print(f\"\\n  Users sample:\")\n",
    "    print(json_transformed['users'][['user_id', 'name', 'username']].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run Complete Pipeline\n",
    "\n",
    "Now let's run the full pipeline for CSV processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process CSV file\n",
    "if csv_file.exists():\n",
    "    os.environ['STORE_KEY'] = 'csv_demo'\n",
    "    pipeline.process_csv('test.csv')\n",
    "    print(\"✓ CSV processing completed!\")\n",
    "    print(\"  → Data extracted, transformed, saved to object store, and loaded to database\")\n",
    "else:\n",
    "    print(\"⚠ CSV file not found - skipping CSV processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Process JSON File\n",
    "\n",
    "Process JSON data which creates multiple linked tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process JSON file\n",
    "if json_file.exists():\n",
    "    os.environ['STORE_KEY'] = 'json_demo'\n",
    "    pipeline.process_json('test.json')\n",
    "    print(\"✓ JSON processing completed!\")\n",
    "    print(\"  → Created 3 tables: users, telephone_numbers, jobs_history\")\n",
    "    print(\"  → All PII masked (emails, phones, national IDs, passwords)\")\n",
    "else:\n",
    "    print(\"⚠ JSON file not found - skipping JSON processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Verify Data in Object Store\n",
    "\n",
    "Check what was saved to the object store (intermediate step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.storage import ObjectStore\n",
    "\n",
    "store = ObjectStore('./output')\n",
    "\n",
    "# Check CSV data in store\n",
    "csv_data = store.load('csv_demo', 'parquet')\n",
    "if csv_data is not None:\n",
    "    print(f\"✓ CSV data in object store: {len(csv_data)} rows\")\n",
    "    print(f\"  Columns: {list(csv_data.columns)}\")\n",
    "\n",
    "# Check JSON data in store\n",
    "json_data_store = store.load('json_demo', 'parquet')\n",
    "if json_data_store is not None:\n",
    "    print(f\"\\n✓ JSON data in object store:\")\n",
    "    for table_name, df in json_data_store.items():\n",
    "        print(f\"  - {table_name}: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Cleanup\n",
    "\n",
    "Close the pipeline to release database connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.close()\n",
    "print(\"✓ Pipeline closed - database connections released\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ETLPipeline' from 'src.pipeline' (/home/anser/Downloads/anserGithub/BoostCredit/src/pipeline.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49411/4140275679.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mETLPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Initialize pipeline with SQLite database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdb_connection_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sqlite:///etl_database.db'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mETLPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_connection_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ETLPipeline' from 'src.pipeline' (/home/anser/Downloads/anserGithub/BoostCredit/src/pipeline.py)"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file exists: True\n",
      "CSV file size: 465.68 MB\n",
      "\n",
      "First 5 rows:\n",
      "     id              name                                            address  \\\n",
      "0  6311    Jennifer Green  7593 Juan Throughway Apt. 948\\nWest Corey, TX ...   \n",
      "1  3350      Karen Grimes    60975 Jessica Squares\\nEast Sallybury, FL 71671   \n",
      "2  9031       Calvin Cook                   PSC 3989, Box 4719\\nAPO AA 42056   \n",
      "3  1131    Peter Mcdowell                   PSC 1868, Box 4833\\nAPO AP 77807   \n",
      "4  1889  Mr. Ryan Sanchez      352 Simmons Circle\\nPort Dustinbury, OK 83627   \n",
      "\n",
      "    color               created_at  last_login is_claimed  paid_amount  \n",
      "0    lime  Monday, June 30th, 2013  1202190735       True  5004.671532  \n",
      "1    lime  Monday, June 30th, 2013   195884769       True   893.404595  \n",
      "2  silver           1986-06-23TEST   623477862       True   266.600000  \n",
      "3    aqua           1998-07-17TEST  1244885561       True   674.544127  \n",
      "4   white      2006-05-09 13:29:58  1293151276      truee          NaN  \n",
      "\n",
      "Columns: ['id', 'name', 'address', 'color', 'created_at', 'last_login', 'is_claimed', 'paid_amount']\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>color</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_login</th>\n",
       "      <th>is_claimed</th>\n",
       "      <th>paid_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6311</td>\n",
       "      <td>Jennifer Green</td>\n",
       "      <td>7593 Juan Throughway Apt. 948\\nWest Corey, TX ...</td>\n",
       "      <td>lime</td>\n",
       "      <td>Monday, June 30th, 2013</td>\n",
       "      <td>1202190735</td>\n",
       "      <td>True</td>\n",
       "      <td>5004.671532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3350</td>\n",
       "      <td>Karen Grimes</td>\n",
       "      <td>60975 Jessica Squares\\nEast Sallybury, FL 71671</td>\n",
       "      <td>lime</td>\n",
       "      <td>Monday, June 30th, 2013</td>\n",
       "      <td>195884769</td>\n",
       "      <td>True</td>\n",
       "      <td>893.404595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9031</td>\n",
       "      <td>Calvin Cook</td>\n",
       "      <td>PSC 3989, Box 4719\\nAPO AA 42056</td>\n",
       "      <td>silver</td>\n",
       "      <td>1986-06-23TEST</td>\n",
       "      <td>623477862</td>\n",
       "      <td>True</td>\n",
       "      <td>266.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1131</td>\n",
       "      <td>Peter Mcdowell</td>\n",
       "      <td>PSC 1868, Box 4833\\nAPO AP 77807</td>\n",
       "      <td>aqua</td>\n",
       "      <td>1998-07-17TEST</td>\n",
       "      <td>1244885561</td>\n",
       "      <td>True</td>\n",
       "      <td>674.544127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889</td>\n",
       "      <td>Mr. Ryan Sanchez</td>\n",
       "      <td>352 Simmons Circle\\nPort Dustinbury, OK 83627</td>\n",
       "      <td>white</td>\n",
       "      <td>2006-05-09 13:29:58</td>\n",
       "      <td>1293151276</td>\n",
       "      <td>truee</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id              name                                            address  \\\n",
       "0  6311    Jennifer Green  7593 Juan Throughway Apt. 948\\nWest Corey, TX ...   \n",
       "1  3350      Karen Grimes    60975 Jessica Squares\\nEast Sallybury, FL 71671   \n",
       "2  9031       Calvin Cook                   PSC 3989, Box 4719\\nAPO AA 42056   \n",
       "3  1131    Peter Mcdowell                   PSC 1868, Box 4833\\nAPO AP 77807   \n",
       "4  1889  Mr. Ryan Sanchez      352 Simmons Circle\\nPort Dustinbury, OK 83627   \n",
       "\n",
       "    color               created_at  last_login is_claimed  paid_amount  \n",
       "0    lime  Monday, June 30th, 2013  1202190735       True  5004.671532  \n",
       "1    lime  Monday, June 30th, 2013   195884769       True   893.404595  \n",
       "2  silver           1986-06-23TEST   623477862       True   266.600000  \n",
       "3    aqua           1998-07-17TEST  1244885561       True   674.544127  \n",
       "4   white      2006-05-09 13:29:58  1293151276      truee          NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8338/3075585581.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check JSON file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjson_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/test.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"JSON file exists: {json_file.exists()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"JSON file size: {json_file.stat().st_size / (1024*1024):.2f} MB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
