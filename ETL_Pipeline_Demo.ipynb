{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoostCredit ETL Pipeline \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ETLPipeline' from 'src.pipeline' (/home/anser/Downloads/anserGithub/BoostCredit/src/pipeline.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49411/4140275679.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mETLPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Initialize pipeline with SQLite database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdb_connection_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sqlite:///etl_database.db'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mETLPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_connection_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ETLPipeline' from 'src.pipeline' (/home/anser/Downloads/anserGithub/BoostCredit/src/pipeline.py)"
     ]
    }
   ],
   "source": [
    "from src.pipeline import ETLPipeline\n",
    "\n",
    "# Initialize pipeline with SQLite database\n",
    "db_connection_string = 'sqlite:///etl_database.db'\n",
    "pipeline = ETLPipeline(db_connection_string)\n",
    "\n",
    "print(f\"✓ ETL Pipeline initialized\")\n",
    "print(f\"✓ Database: {db_connection_string}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file exists: True\n",
      "CSV file size: 465.68 MB\n",
      "\n",
      "First 5 rows:\n",
      "     id              name                                            address  \\\n",
      "0  6311    Jennifer Green  7593 Juan Throughway Apt. 948\\nWest Corey, TX ...   \n",
      "1  3350      Karen Grimes    60975 Jessica Squares\\nEast Sallybury, FL 71671   \n",
      "2  9031       Calvin Cook                   PSC 3989, Box 4719\\nAPO AA 42056   \n",
      "3  1131    Peter Mcdowell                   PSC 1868, Box 4833\\nAPO AP 77807   \n",
      "4  1889  Mr. Ryan Sanchez      352 Simmons Circle\\nPort Dustinbury, OK 83627   \n",
      "\n",
      "    color               created_at  last_login is_claimed  paid_amount  \n",
      "0    lime  Monday, June 30th, 2013  1202190735       True  5004.671532  \n",
      "1    lime  Monday, June 30th, 2013   195884769       True   893.404595  \n",
      "2  silver           1986-06-23TEST   623477862       True   266.600000  \n",
      "3    aqua           1998-07-17TEST  1244885561       True   674.544127  \n",
      "4   white      2006-05-09 13:29:58  1293151276      truee          NaN  \n",
      "\n",
      "Columns: ['id', 'name', 'address', 'color', 'created_at', 'last_login', 'is_claimed', 'paid_amount']\n"
     ]
    }
   ],
   "source": [
    "# Check CSV file\n",
    "csv_file = Path('data/test.csv')\n",
    "print(f\"CSV file exists: {csv_file.exists()}\")\n",
    "print(f\"CSV file size: {csv_file.stat().st_size / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Preview first few rows\n",
    "if csv_file.exists():\n",
    "    df_preview = pd.read_csv(csv_file, nrows=5)\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df_preview)\n",
    "    print(f\"\\nColumns: {list(df_preview.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>color</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_login</th>\n",
       "      <th>is_claimed</th>\n",
       "      <th>paid_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6311</td>\n",
       "      <td>Jennifer Green</td>\n",
       "      <td>7593 Juan Throughway Apt. 948\\nWest Corey, TX ...</td>\n",
       "      <td>lime</td>\n",
       "      <td>Monday, June 30th, 2013</td>\n",
       "      <td>1202190735</td>\n",
       "      <td>True</td>\n",
       "      <td>5004.671532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3350</td>\n",
       "      <td>Karen Grimes</td>\n",
       "      <td>60975 Jessica Squares\\nEast Sallybury, FL 71671</td>\n",
       "      <td>lime</td>\n",
       "      <td>Monday, June 30th, 2013</td>\n",
       "      <td>195884769</td>\n",
       "      <td>True</td>\n",
       "      <td>893.404595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9031</td>\n",
       "      <td>Calvin Cook</td>\n",
       "      <td>PSC 3989, Box 4719\\nAPO AA 42056</td>\n",
       "      <td>silver</td>\n",
       "      <td>1986-06-23TEST</td>\n",
       "      <td>623477862</td>\n",
       "      <td>True</td>\n",
       "      <td>266.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1131</td>\n",
       "      <td>Peter Mcdowell</td>\n",
       "      <td>PSC 1868, Box 4833\\nAPO AP 77807</td>\n",
       "      <td>aqua</td>\n",
       "      <td>1998-07-17TEST</td>\n",
       "      <td>1244885561</td>\n",
       "      <td>True</td>\n",
       "      <td>674.544127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889</td>\n",
       "      <td>Mr. Ryan Sanchez</td>\n",
       "      <td>352 Simmons Circle\\nPort Dustinbury, OK 83627</td>\n",
       "      <td>white</td>\n",
       "      <td>2006-05-09 13:29:58</td>\n",
       "      <td>1293151276</td>\n",
       "      <td>truee</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id              name                                            address  \\\n",
       "0  6311    Jennifer Green  7593 Juan Throughway Apt. 948\\nWest Corey, TX ...   \n",
       "1  3350      Karen Grimes    60975 Jessica Squares\\nEast Sallybury, FL 71671   \n",
       "2  9031       Calvin Cook                   PSC 3989, Box 4719\\nAPO AA 42056   \n",
       "3  1131    Peter Mcdowell                   PSC 1868, Box 4833\\nAPO AP 77807   \n",
       "4  1889  Mr. Ryan Sanchez      352 Simmons Circle\\nPort Dustinbury, OK 83627   \n",
       "\n",
       "    color               created_at  last_login is_claimed  paid_amount  \n",
       "0    lime  Monday, June 30th, 2013  1202190735       True  5004.671532  \n",
       "1    lime  Monday, June 30th, 2013   195884769       True   893.404595  \n",
       "2  silver           1986-06-23TEST   623477862       True   266.600000  \n",
       "3    aqua           1998-07-17TEST  1244885561       True   674.544127  \n",
       "4   white      2006-05-09 13:29:58  1293151276      truee          NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preview.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process CSV file\n",
    "print(\"Processing CSV file...\")\n",
    "pipeline.process_csv(str(csv_file), 'test')\n",
    "print(\"✓ CSV processing completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database and query test table\n",
    "engine = create_engine(db_connection_string)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    # Get row count\n",
    "    result = conn.execute(text(\"SELECT COUNT(*) as count FROM test\"))\n",
    "    row_count = result.fetchone()[0]\n",
    "    print(f\"Total rows in 'test' table: {row_count}\")\n",
    "    \n",
    "    # Get sample data\n",
    "    result = conn.execute(text(\"SELECT * FROM test LIMIT 5\"))\n",
    "    columns = result.keys()\n",
    "    rows = result.fetchall()\n",
    "    \n",
    "    print(\"\\nSample data from 'test' table:\")\n",
    "    df_test = pd.DataFrame(rows, columns=columns)\n",
    "    print(df_test)\n",
    "    \n",
    "    # Check data types\n",
    "    print(\"\\nData types:\")\n",
    "    result = conn.execute(text(\"PRAGMA table_info(test)\"))\n",
    "    schema = result.fetchall()\n",
    "    for col in schema:\n",
    "        print(f\"  {col[1]}: {col[2]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8338/3075585581.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check JSON file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjson_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/test.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"JSON file exists: {json_file.exists()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"JSON file size: {json_file.stat().st_size / (1024*1024):.2f} MB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "# Check JSON file\n",
    "json_file = Path('data/test.json')\n",
    "print(f\"JSON file exists: {json_file.exists()}\")\n",
    "print(f\"JSON file size: {json_file.stat().st_size / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Preview first record\n",
    "if json_file.exists():\n",
    "    import json\n",
    "    with open(json_file, 'r') as f:\n",
    "        first_line = f.readline()\n",
    "        first_record = json.loads(first_line)\n",
    "        print(\"\\nFirst record structure:\")\n",
    "        print(json.dumps(first_record, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process JSON file\n",
    "print(\"Processing JSON file...\")\n",
    "pipeline.process_json(str(json_file))\n",
    "print(\"✓ JSON processing completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Verify JSON Data in Database\n",
    "\n",
    "Let's verify that the three tables (`users`, `telephone_numbers`, `jobs_history`) were created and populated correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify users table\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT COUNT(*) as count FROM users\"))\n",
    "    user_count = result.fetchone()[0]\n",
    "    print(f\"Total users: {user_count}\")\n",
    "    \n",
    "    result = conn.execute(text(\"SELECT * FROM users LIMIT 3\"))\n",
    "    columns = result.keys()\n",
    "    rows = result.fetchall()\n",
    "    df_users = pd.DataFrame(rows, columns=columns)\n",
    "    print(\"\\nSample users (with PII masked):\")\n",
    "    print(df_users[['user_id', 'name', 'username', 'national_id']].to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify telephone_numbers table\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT COUNT(*) as count FROM telephone_numbers\"))\n",
    "    tel_count = result.fetchone()[0]\n",
    "    print(f\"Total telephone numbers: {tel_count}\")\n",
    "    \n",
    "    result = conn.execute(text(\"\"\"\n",
    "        SELECT tn.*, u.name \n",
    "        FROM telephone_numbers tn\n",
    "        JOIN users u ON tn.user_id = u.user_id\n",
    "        LIMIT 5\n",
    "    \"\"\"))\n",
    "    columns = result.keys()\n",
    "    rows = result.fetchall()\n",
    "    df_tel = pd.DataFrame(rows, columns=columns)\n",
    "    print(\"\\nSample telephone numbers (with PII masked):\")\n",
    "    print(df_tel[['user_id', 'name', 'telephone_number']].to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify jobs_history table\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT COUNT(*) as count FROM jobs_history\"))\n",
    "    job_count = result.fetchone()[0]\n",
    "    print(f\"Total job history records: {job_count}\")\n",
    "    \n",
    "    result = conn.execute(text(\"\"\"\n",
    "        SELECT jh.*, u.name \n",
    "        FROM jobs_history jh\n",
    "        JOIN users u ON jh.user_id = u.user_id\n",
    "        LIMIT 5\n",
    "    \"\"\"))\n",
    "    columns = result.keys()\n",
    "    rows = result.fetchall()\n",
    "    df_jobs = pd.DataFrame(rows, columns=columns)\n",
    "    print(\"\\nSample job history:\")\n",
    "    print(df_jobs[['user_id', 'name', 'occupation', 'start', 'end', 'is_fulltime']].to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Verify Foreign Key Relationships\n",
    "\n",
    "Let's verify that the foreign key relationships are working correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify relationships\n",
    "with engine.connect() as conn:\n",
    "    # Check users with telephone numbers\n",
    "    result = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            u.user_id,\n",
    "            u.name,\n",
    "            COUNT(tn.telephone_number) as phone_count,\n",
    "            COUNT(jh.job_id) as job_count\n",
    "        FROM users u\n",
    "        LEFT JOIN telephone_numbers tn ON u.user_id = tn.user_id\n",
    "        LEFT JOIN jobs_history jh ON u.user_id = jh.user_id\n",
    "        GROUP BY u.user_id, u.name\n",
    "        LIMIT 10\n",
    "    \"\"\"))\n",
    "    columns = result.keys()\n",
    "    rows = result.fetchall()\n",
    "    df_relationships = pd.DataFrame(rows, columns=columns)\n",
    "    print(\"Users with their telephone numbers and job counts:\")\n",
    "    print(df_relationships.to_string())\n",
    "    \n",
    "    print(\"\\n✓ Foreign key relationships verified!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Summary Statistics\n",
    "\n",
    "Let's get a summary of all the data loaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "with engine.connect() as conn:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ETL Pipeline Summary\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test table\n",
    "    result = conn.execute(text(\"SELECT COUNT(*) FROM test\"))\n",
    "    test_count = result.fetchone()[0]\n",
    "    print(f\"\\n✓ Test table: {test_count:,} rows\")\n",
    "    \n",
    "    # Users table\n",
    "    result = conn.execute(text(\"SELECT COUNT(*) FROM users\"))\n",
    "    users_count = result.fetchone()[0]\n",
    "    print(f\"✓ Users table: {users_count:,} rows\")\n",
    "    \n",
    "    # Telephone numbers\n",
    "    result = conn.execute(text(\"SELECT COUNT(*) FROM telephone_numbers\"))\n",
    "    tel_count = result.fetchone()[0]\n",
    "    print(f\"✓ Telephone numbers table: {tel_count:,} rows\")\n",
    "    \n",
    "    # Jobs history\n",
    "    result = conn.execute(text(\"SELECT COUNT(*) FROM jobs_history\"))\n",
    "    jobs_count = result.fetchone()[0]\n",
    "    print(f\"✓ Jobs history table: {jobs_count:,} rows\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✓ All data successfully loaded and verified!\")\n",
    "    print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close pipeline\n",
    "pipeline.close()\n",
    "print(\"✓ Pipeline closed successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
