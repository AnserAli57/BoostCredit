{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoostCredit ETL Pipeline Demo\n",
    "\n",
    "This notebook demonstrates the ETL pipeline for processing CSV and JSON data.\n",
    "\n",
    "## Pipeline Flow:\n",
    "1. **Extract** → Read data from CSV/JSON files\n",
    "2. **Transform** → Clean, convert types, mask PII\n",
    "3. **Store** → Save to object store (Parquet)\n",
    "4. **Load** → Load from object store to PostgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment variables set\n",
      "✓ Modules reloaded and imports successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Reload modules to ensure we have the latest code (important for notebooks)\n",
    "import src.loaders\n",
    "import src.pipeline\n",
    "import src.extractors\n",
    "import src.transformers\n",
    "\n",
    "\n",
    "from src.pipeline import Pipeline\n",
    "from src.extractors import CSVExtractor, JSONExtractor\n",
    "from src.transformers import CSVTransformer, JSONTransformer\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['STORE_KEY'] = 'demo_data'\n",
    "os.environ['DB_TYPE'] = 'postgresql'\n",
    "os.environ['DB_HOST'] = 'localhost'\n",
    "os.environ['DB_PORT'] = '5432'\n",
    "os.environ['DB_USER'] = 'etl_user'\n",
    "os.environ['DB_PASSWORD'] = 'etl_password'\n",
    "os.environ['DB_NAME'] = 'etl_database'\n",
    "os.environ['DATA_PATH'] = './data'\n",
    "os.environ['OBJECT_STORE_PATH'] = './output'\n",
    "\n",
    "print(\"✓ Environment variables set\")\n",
    "print(\"✓ Modules reloaded and imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize Pipeline\n",
    "\n",
    "The pipeline handles the complete ETL process automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Pipeline initialized\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "print(\"✓ Pipeline initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Test Individual Components\n",
    "\n",
    "Let's test each component separately to understand what they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CSV Extracted: 4000000 rows\n",
      "  Columns: ['id', 'name', 'address', 'color', 'created_at', 'last_login', 'is_claimed', 'paid_amount']\n",
      "\n",
      "  First row sample:\n",
      "     id            name                                            address  \\\n",
      "0  6311  Jennifer Green  7593 Juan Throughway Apt. 948\\nWest Corey, TX ...   \n",
      "\n",
      "  color               created_at  last_login is_claimed  paid_amount  \n",
      "0  lime  Monday, June 30th, 2013  1202190735       True  5004.671532  \n"
     ]
    }
   ],
   "source": [
    "# Test CSV Extractor\n",
    "csv_extractor = CSVExtractor()\n",
    "csv_file = Path('data/test.csv')\n",
    "if csv_file.exists():\n",
    "    sample_data = csv_extractor.extract(str(csv_file))\n",
    "    print(f\"✓ CSV Extracted: {len(sample_data)} rows\")\n",
    "    print(f\"  Columns: {list(sample_data.columns)}\")\n",
    "    print(f\"\\n  First row sample:\")\n",
    "    print(sample_data.head(1))\n",
    "else:\n",
    "    print(\"⚠ CSV file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>color</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_login</th>\n",
       "      <th>is_claimed</th>\n",
       "      <th>paid_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6311</td>\n",
       "      <td>Jennifer Green</td>\n",
       "      <td>7593 Juan Throughway Apt. 948\\nWest Corey, TX ...</td>\n",
       "      <td>lime</td>\n",
       "      <td>Monday, June 30th, 2013</td>\n",
       "      <td>1202190735</td>\n",
       "      <td>True</td>\n",
       "      <td>5004.671532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3350</td>\n",
       "      <td>Karen Grimes</td>\n",
       "      <td>60975 Jessica Squares\\nEast Sallybury, FL 71671</td>\n",
       "      <td>lime</td>\n",
       "      <td>Monday, June 30th, 2013</td>\n",
       "      <td>195884769</td>\n",
       "      <td>True</td>\n",
       "      <td>893.40459503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9031</td>\n",
       "      <td>Calvin Cook</td>\n",
       "      <td>PSC 3989, Box 4719\\nAPO AA 42056</td>\n",
       "      <td>silver</td>\n",
       "      <td>1986-06-23TEST</td>\n",
       "      <td>623477862</td>\n",
       "      <td>True</td>\n",
       "      <td>266.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1131</td>\n",
       "      <td>Peter Mcdowell</td>\n",
       "      <td>PSC 1868, Box 4833\\nAPO AP 77807</td>\n",
       "      <td>aqua</td>\n",
       "      <td>1998-07-17TEST</td>\n",
       "      <td>1244885561</td>\n",
       "      <td>True</td>\n",
       "      <td>674.5441267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889</td>\n",
       "      <td>Mr. Ryan Sanchez</td>\n",
       "      <td>352 Simmons Circle\\nPort Dustinbury, OK 83627</td>\n",
       "      <td>white</td>\n",
       "      <td>2006-05-09 13:29:58</td>\n",
       "      <td>1293151276</td>\n",
       "      <td>truee</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id              name                                            address  \\\n",
       "0  6311    Jennifer Green  7593 Juan Throughway Apt. 948\\nWest Corey, TX ...   \n",
       "1  3350      Karen Grimes    60975 Jessica Squares\\nEast Sallybury, FL 71671   \n",
       "2  9031       Calvin Cook                   PSC 3989, Box 4719\\nAPO AA 42056   \n",
       "3  1131    Peter Mcdowell                   PSC 1868, Box 4833\\nAPO AP 77807   \n",
       "4  1889  Mr. Ryan Sanchez      352 Simmons Circle\\nPort Dustinbury, OK 83627   \n",
       "\n",
       "    color               created_at  last_login is_claimed   paid_amount  \n",
       "0    lime  Monday, June 30th, 2013  1202190735       True   5004.671532  \n",
       "1    lime  Monday, June 30th, 2013   195884769       True  893.40459503  \n",
       "2  silver           1986-06-23TEST   623477862       True         266.6  \n",
       "3    aqua           1998-07-17TEST  1244885561       True   674.5441267  \n",
       "4   white      2006-05-09 13:29:58  1293151276      truee           NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CSV Transformed\n",
      "  Data types converted\n",
      "  PII masked (name, address)\n",
      "\n",
      "  Transformed sample:\n",
      "     id       name created_at  is_claimed  paid_amount\n",
      "0  6311  J*** G*** 2013-06-30        True      5004.67\n",
      "1  3350  K*** G*** 2013-06-30        True       893.40\n"
     ]
    }
   ],
   "source": [
    "# Test CSV Transformer\n",
    "csv_transformer = CSVTransformer()\n",
    "if csv_file.exists():\n",
    "    transformed = csv_transformer.transform(sample_data.head(5))\n",
    "    print(\"✓ CSV Transformed\")\n",
    "    print(f\"  Data types converted\")\n",
    "    print(f\"  PII masked (name, address)\")\n",
    "    print(f\"\\n  Transformed sample:\")\n",
    "    print(transformed[['id', 'name', 'created_at', 'is_claimed', 'paid_amount']].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>color</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_login</th>\n",
       "      <th>is_claimed</th>\n",
       "      <th>paid_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6311</td>\n",
       "      <td>J*** G***</td>\n",
       "      <td>*****************************\\nWest Corey, TX ...</td>\n",
       "      <td>lime</td>\n",
       "      <td>2013-06-30 00:00:00</td>\n",
       "      <td>2008-02-05 10:52:15</td>\n",
       "      <td>True</td>\n",
       "      <td>5004.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3350</td>\n",
       "      <td>K*** G***</td>\n",
       "      <td>*********************\\nEast Sallybury, FL 71671</td>\n",
       "      <td>lime</td>\n",
       "      <td>2013-06-30 00:00:00</td>\n",
       "      <td>1976-03-17 09:26:09</td>\n",
       "      <td>True</td>\n",
       "      <td>893.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9031</td>\n",
       "      <td>C*** C***</td>\n",
       "      <td>******************\\nAPO AA 42056</td>\n",
       "      <td>silver</td>\n",
       "      <td>1986-06-23 00:00:00</td>\n",
       "      <td>1989-10-04 09:17:42</td>\n",
       "      <td>True</td>\n",
       "      <td>266.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1131</td>\n",
       "      <td>P*** M***</td>\n",
       "      <td>******************\\nAPO AP 77807</td>\n",
       "      <td>aqua</td>\n",
       "      <td>1998-07-17 00:00:00</td>\n",
       "      <td>2009-06-13 15:32:41</td>\n",
       "      <td>True</td>\n",
       "      <td>674.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889</td>\n",
       "      <td>M*** S***</td>\n",
       "      <td>******************\\nPort Dustinbury, OK 83627</td>\n",
       "      <td>white</td>\n",
       "      <td>2006-05-09 13:29:58</td>\n",
       "      <td>2010-12-24 05:41:16</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id       name                                            address   color  \\\n",
       "0  6311  J*** G***  *****************************\\nWest Corey, TX ...    lime   \n",
       "1  3350  K*** G***    *********************\\nEast Sallybury, FL 71671    lime   \n",
       "2  9031  C*** C***                   ******************\\nAPO AA 42056  silver   \n",
       "3  1131  P*** M***                   ******************\\nAPO AP 77807    aqua   \n",
       "4  1889  M*** S***      ******************\\nPort Dustinbury, OK 83627   white   \n",
       "\n",
       "           created_at          last_login  is_claimed  paid_amount  \n",
       "0 2013-06-30 00:00:00 2008-02-05 10:52:15        True      5004.67  \n",
       "1 2013-06-30 00:00:00 1976-03-17 09:26:09        True       893.40  \n",
       "2 1986-06-23 00:00:00 1989-10-04 09:17:42        True       266.60  \n",
       "3 1998-07-17 00:00:00 2009-06-13 15:32:41        True       674.54  \n",
       "4 2006-05-09 13:29:58 2010-12-24 05:41:16        True          NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ JSON Extracted: 100000 records\n",
      "\n",
      "  First record keys: ['user_id', 'created_at', 'updated_at', 'logged_at', 'user_details', 'jobs_history']\n",
      "  Sample user_id: e9703a66-6556-4b48-8a0b-0ace129d7a11\n"
     ]
    }
   ],
   "source": [
    "# Test JSON Extractor\n",
    "json_extractor = JSONExtractor()\n",
    "json_file = Path('data/test.json')\n",
    "if json_file.exists():\n",
    "    json_data = json_extractor.extract(str(json_file))\n",
    "    print(f\"✓ JSON Extracted: {len(json_data)} records\")\n",
    "    print(f\"\\n  First record keys: {list(json_data[0].keys())}\")\n",
    "    print(f\"  Sample user_id: {json_data[0].get('user_id', 'N/A')}\")\n",
    "else:\n",
    "    print(\"⚠ JSON file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ JSON Transformed into 3 tables:\n",
      "  - users: 2 rows\n",
      "  - telephone_numbers: 4 rows\n",
      "  - jobs_history: 2 rows\n",
      "\n",
      "  Users sample:\n",
      "                                user_id       name  \\\n",
      "0  e9703a66-6556-4b48-8a0b-0ace129d7a11  J*** W***   \n",
      "1  aa246388-104c-44f7-93f4-4b688dc0baff  S*** H***   \n",
      "\n",
      "                       username  \n",
      "0      b****e@garza-shelton.net  \n",
      "1  h********s@baker-beasley.com  \n"
     ]
    }
   ],
   "source": [
    "# Test JSON Transformer\n",
    "json_transformer = JSONTransformer()\n",
    "if json_file.exists():\n",
    "    json_transformed = json_transformer.transform(json_data[:2])  # Transform 2 records\n",
    "    print(\"✓ JSON Transformed into 3 tables:\")\n",
    "    print(f\"  - users: {len(json_transformed['users'])} rows\")\n",
    "    print(f\"  - telephone_numbers: {len(json_transformed['telephone_numbers'])} rows\")\n",
    "    print(f\"  - jobs_history: {len(json_transformed['jobs_history'])} rows\")\n",
    "    print(f\"\\n  Users sample:\")\n",
    "    print(json_transformed['users'][['user_id', 'name', 'username']].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'users':                                 user_id created_at updated_at  \\\n",
       " 0  e9703a66-6556-4b48-8a0b-0ace129d7a11 2003-09-19 1986-01-02   \n",
       " 1  aa246388-104c-44f7-93f4-4b688dc0baff 2002-10-08 1984-08-26   \n",
       " \n",
       "             logged_at       name         dob  \\\n",
       " 0 1997-12-12 05:03:28  J*** W***  1983-05-15   \n",
       " 1 1972-06-10 17:46:40  S*** H***  1996-09-24   \n",
       " \n",
       "                                        address                      username  \\\n",
       " 0         **************\\nNorth Dana, MN 35292      b****e@garza-shelton.net   \n",
       " 1  ******************\\nPort Kimmouth, MI 12236  h********s@baker-beasley.com   \n",
       " \n",
       "      password national_id  \n",
       " 0  **********   *****8140  \n",
       " 1  **********   *****4594  ,\n",
       " 'telephone_numbers':                                 user_id    telephone_number\n",
       " 0  e9703a66-6556-4b48-8a0b-0ace129d7a11    ************7268\n",
       " 1  e9703a66-6556-4b48-8a0b-0ace129d7a11  **************5397\n",
       " 2  aa246388-104c-44f7-93f4-4b688dc0baff          ******9845\n",
       " 3  aa246388-104c-44f7-93f4-4b688dc0baff    ************0701,\n",
       " 'jobs_history':                                  job_id                               user_id  \\\n",
       " 0  8c48a084-27d7-4f13-98fe-10b802275103  e9703a66-6556-4b48-8a0b-0ace129d7a11   \n",
       " 1  b9d4fc47-0e53-4494-84ae-a39f446be0c9  aa246388-104c-44f7-93f4-4b688dc0baff   \n",
       " \n",
       "        occupation  is_fulltime       start         end employer  \n",
       " 0    Set designer        False  1996-12-26  1997-10-02     None  \n",
       " 1  Chief of Staff         True  1991-09-12  2015-08-04     None  }"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run Complete Pipeline\n",
    "\n",
    "Now let's run the full pipeline for CSV processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process CSV file\n",
    "if csv_file.exists():\n",
    "    os.environ['STORE_KEY'] = 'csv_demo'\n",
    "    pipeline.process_csv('test.csv')\n",
    "    print(\"✓ CSV processing completed!\")\n",
    "    print(\"  → Data extracted, transformed, saved to object store, and loaded to database\")\n",
    "else:\n",
    "    print(\"⚠ CSV file not found - skipping CSV processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Process JSON File\n",
    "\n",
    "Process JSON data which creates multiple linked tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process JSON file\n",
    "if json_file.exists():\n",
    "    os.environ['STORE_KEY'] = 'json_demo'\n",
    "    pipeline.process_json('test.json')\n",
    "    print(\"✓ JSON processing completed!\")\n",
    "    print(\"  → Created 3 tables: users, telephone_numbers, jobs_history\")\n",
    "    print(\"  → All PII masked (emails, phones, national IDs, passwords)\")\n",
    "else:\n",
    "    print(\"⚠ JSON file not found - skipping JSON processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Verify Data in Object Store\n",
    "\n",
    "Check what was saved to the object store (intermediate step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.storage import ObjectStore\n",
    "\n",
    "store = ObjectStore('./output')\n",
    "\n",
    "# Check CSV data in store\n",
    "csv_data = store.load('csv_demo', 'parquet')\n",
    "if csv_data is not None:\n",
    "    print(f\"✓ CSV data in object store: {len(csv_data)} rows\")\n",
    "    print(f\"  Columns: {list(csv_data.columns)}\")\n",
    "\n",
    "# Check JSON data in store\n",
    "json_data_store = store.load('json_demo', 'parquet')\n",
    "if json_data_store is not None:\n",
    "    print(f\"\\n✓ JSON data in object store:\")\n",
    "    for table_name, df in json_data_store.items():\n",
    "        print(f\"  - {table_name}: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Cleanup\n",
    "\n",
    "Close the pipeline to release database connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.close()\n",
    "print(\"✓ Pipeline closed - database connections released\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
